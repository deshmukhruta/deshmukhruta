{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geopandas\n",
    "# !pip install pgeocode\n",
    "# !pip install folium\n",
    "# !pip install pyshp\n",
    "# !pip install haversine\n",
    "# !pip install k-means-constrained\n",
    "# !pip install k-means-constrained --target /opt/conda/lib/python3.8/site-packages\n",
    "# !pip install --upgrade numpy --target /opt/conda/lib/python3.8/site-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get fake jobs for zipcodes in Orlando\n",
    "# 2) Get problem descriptions for the jobs and predict parts START HERE\n",
    "# 3) Create part stock list - top 10 model ice maker kits\n",
    "# 4) Flag same day fix\n",
    "# 5) run against current availibility mapping with agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sqlalchemy, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(201912)\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import pickle\n",
    "from retail_toolkit import atlas\n",
    "from retail_toolkit import credential_manager as cm\n",
    "from numpy import average\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from collections import Counter\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import plugins\n",
    "# import geopandas as gpd\n",
    "from folium.plugins import HeatMap\n",
    "from shapely.geometry import Point, Polygon\n",
    "import shapefile\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_means_constrained import KMeansConstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgeocode\n",
    "from haversine import haversine, Unit\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying simple kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import get_coverage\n",
    "import color_scheme\n",
    "mapping = color_scheme.create_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demand():\n",
    "    presto_connection =  atlas.Presto(environment = 'presto://{}:{}@atlas-workbench-presto.atlas.prd.aws.asurion.net:18443/hive').connect()\n",
    "    sql = \"\"\"\n",
    "    select distinct\n",
    "        sj.service_order_id ,\n",
    "        so.service_order_number,\n",
    "        sj.service_job_type_id ,\n",
    "        sj.payment_type ,\n",
    "        sj.sj_program_id ,\n",
    "        sj.external_reference_number ,\n",
    "        sj.crm_number ,\n",
    "        sj.service_job_id ,\n",
    "        sj.service_job_number ,\n",
    "        sj.service_job_status ,\n",
    "        sj.service_job_sub_status ,\n",
    "        sj.service_job_date,\n",
    "        sj.service_job_source ,\n",
    "        sj.service_request_type_code ,\n",
    "        sj.technician_routing_status ,\n",
    "        sj.technician_routing_message ,\n",
    "        sj.route_order_number ,\n",
    "        sj.scheduled_service_date,\n",
    "        coalesce(o.orig_sched_dt, sj.scheduled_service_date) orig_service_dt ,\n",
    "        sj.problem_description ,\n",
    "        sj.service_explanation ,\n",
    "        sj.technician_id ,\n",
    "        rs.retailer_store_name,\n",
    "        sprd.model_number,\n",
    "        sprd.model_version,\n",
    "        sprd.serial_number,\n",
    "        sprd.internal_brand_code ,\n",
    "        sprd.purchase_date ,\n",
    "        sprd.purchase_price ,\n",
    "        sprd.manufacturer ,\n",
    "        sjpl.description industry,\n",
    "        ftf.min_tech_arrival_dt,\n",
    "        ftf.min_complete_dt,\n",
    "        cus.address_line_1 addr_line_1,\n",
    "        cus.address_city,\n",
    "        cus.address_province addr_state,\n",
    "        cus.address_postal_code addr_zip_code,\n",
    "        dl.name\n",
    "    from\n",
    "        hive.rtm_analytics.l2_odhsb_sbv5_at_service_job_rs sj \n",
    "        join hive.rtm_analytics.l2_odhsb_sbv5_at_service_order_rs so on so.service_order_id = sj.service_order_id \n",
    "        left join hive.rtm_analytics.l2_odhsb_sbv5_at_sj_part_rs sjp on sj.service_job_id = sjp.service_job_id\n",
    "        join hive.rtm_analytics.l2_odhsb_sbv5_at_sa_retailer_store_rs rs on\tsj.retailer_store_id = rs.retailer_store_id\n",
    "        join hive.l2_retail.odhsb_sbv5_at_so_product sprd on sprd.service_order_id = so.service_order_id \n",
    "        join hive.l2_retail.odhsb_sbv5_at_sa_service_job_product_line sjpl on sjpl.sj_product_line_id = sprd.sj_product_line_id \n",
    "        join hive.l2_retail.odhsb_sbv5_st_txn_contact cus on cus.txn_id = sj.service_order_id and contact_type = 0\n",
    "        left join hive.l2_retail.odhsb_sb_svbt_dispatch_zone z on sj.sj_zone_id = z.zone_id_char\n",
    "        left join hive.l2_retail.odhsb_sb_svbt_dealer_location dl on z.dealer_location_id = dl.dealer_location_id\n",
    "        left join (\n",
    "            select\n",
    "                entity_id,\n",
    "                min(date_parse(old_value , '%%m/%%d/%%Y')) orig_sched_dt\n",
    "            from\n",
    "                hive.rtm_analytics.l2_odhsb_sbv5_st_audit_field_rs\n",
    "            where\n",
    "                owner_company_id = '43'\n",
    "                and field_id = 'scheduledServiceDate'\n",
    "                and cast(audit_date as date) >= date '2021-01-01'\n",
    "            group by 1\n",
    "        ) o on sj.service_job_id = o.entity_id\n",
    "        left join (\n",
    "            select \n",
    "                so.service_order_id,\n",
    "                min(case when au.new_value = 'TAR' then au.audit_dateutc end) min_tech_arrival_dt,\n",
    "                min(case when au.new_value in ('AAA','AWT','ACU','RTC','AAK','AAJ','ABB','ABC','ACP','ACQ','ACR','ACV') then au.audit_dateutc end) min_complete_dt\n",
    "            from\n",
    "                hive.rtm_analytics.l2_odhsb_sbv5_st_audit_field_rs au\n",
    "                join rtm_analytics.l2_odhsb_sbv5_at_service_job_rs  sj on au.entity_id = sj.service_job_id\n",
    "                join l2_retail.odhsb_sbv5_at_service_order so on so.service_order_id = sj.service_order_id\n",
    "                join rtm_analytics.l2_odhsb_sbv5_at_txn_exception_rs e on e.txn_id = sj.service_job_id\n",
    "                join rtm_analytics.l2_odhsb_sbv5_at_txn_exception_detail_rs ed on ed.exception_id  = e.exception_id and ed.exception_code = 'PRE_DIAGNOSIS'\n",
    "            where\n",
    "                au.owner_company_id = '43'\n",
    "                and cast(au.audit_date as date) >= date '2021-01-01'\n",
    "                and au.field_id = 'serviceJobSubStatus'\n",
    "            group by\n",
    "                so.service_order_id\n",
    "        ) ftf on ftf.service_order_id = so.service_order_id\n",
    "    where\n",
    "        --exception_code = 'PRE_DIAGNOSIS'\n",
    "    -- \tand payment_type = 'CASHONDELIVERY'\n",
    "    -- and retailer_store_name = 'Major Appliance - Samsung'\n",
    "    --sjpl.description IN ('HOME REFRIGERATION' , 'HOME LAUNDRY ELEC', 'HOME LAUNDRY GAS', 'DISHWASHER')\n",
    "        cast(sj.scheduled_service_date as date) >= cast(date_add('month',-12,current_date) as date)\n",
    "        and sj.service_provider_id in ('1133787699','1116738095','1115480731')\n",
    "        and sj.service_job_status in ('CMP','ACC')\n",
    "    \"\"\"\n",
    "    demand = pd.read_sql(sql, presto_connection)\n",
    "    demand = demand[~demand.addr_zip_code.isna()]\n",
    "    demand = demand[demand.addr_zip_code != 'UNKNOWN']\n",
    "    demand['cust_zip'] = demand.addr_zip_code.str[:5]\n",
    "    demand = demand[demand['cust_zip'].apply(lambda x: x.isnumeric())]\n",
    "    demand['cust_zip'] = demand['cust_zip'].astype(int)\n",
    "\n",
    "    return(demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_coverage():\n",
    "    presto_connection =  atlas.Presto(environment = 'presto://{}:{}@edp-workbench-adhoc.edp.prd.aws.asurion.net:18443/hive').connect()\n",
    "    coverage_sql = \"\"\"\n",
    "    select \n",
    "        com.name,\n",
    "        sp.service_provider_id,\n",
    "        dl.name location_name,\n",
    "        atlasdecrypt(dl.address_line1_token) address,\n",
    "        dl.address_city,\n",
    "        dl.address_state,\n",
    "        dl.address_zip,\n",
    "        spl.service_provider_location_id,\n",
    "        sjz.sj_zone_id,\n",
    "        sjz.time_zone,\n",
    "        cov.*\n",
    "    from\n",
    "        l2_retail.odhsb_sbv5_at_sa_service_provider sp \n",
    "        join hive.l2_retail.odhsb_sb_svbt_company com on sp.service_provider_id = com.company_id_char\n",
    "        join l2_retail.odhsb_sbv5_at_service_provider_location spl on sp.service_provider_id = spl.service_provider_id \n",
    "        join hive.l2_retail.odhsb_sb_svbt_dealer_location dl on dl.dealer_location_id_char = spl.service_provider_location_id\n",
    "    --  join l2_retail.odhsb_servicebenchv5_at_sj_first_avail_request far on \n",
    "        join l2_retail.odhsb_servicebenchv5_at_sp_service_job_zone sjz on sjz.service_provider_location_id = spl.service_provider_location_id \n",
    "    --    join hive.l2_retail.odhsb_servicebenchv5_at_sp_sj_zone_coverage_change sjzc on sjzc.sj_zone_id = sjz.sj_zone_id\n",
    "        join hive.l2_retail.odhsb_servicebench_svbt_dealer_zone_coverage cov on cov.zone_id_char = sjz.sj_zone_id\n",
    "    --    join l2_retail.odhsb_servicebench_svbt_dealer_loc_coverage dlc on cast(dlc.dealer_location_id as varchar)  = spl.service_provider_location_id \n",
    "    --  join l2_retail.odhsb_servicebench_svbt_manufacturer_dealer_loc mdl on mdl\n",
    "    --    join l2_retail.odhsb_servicebenchv5_at_sp_sj_availability ssa on sjz.sj_zone_id = ssa.sj_zone_id \n",
    "    where \n",
    "        sp.service_administrator_id = '43'\n",
    "    --    and sp.account_number = '0117521'\n",
    "        --and com.name = 'ASURION REPAIR SERVICES'\n",
    "        and sp.service_provider_id in ('1133787699','1116738095','1115480731')\n",
    "        --and sjz.sj_zone_id = '1138146988'\n",
    "    \"\"\"\n",
    "    coverage = pd.read_sql(coverage_sql, presto_connection)\n",
    "    if coverage.shape[0] >0:\n",
    "        print('Sucessfully read coverage per market')\n",
    "        coverage['location_name'] = coverage['location_name'].str.lower()\n",
    "        return(coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_market_coverage(market_name):\n",
    "    coverage = get_market_coverage()\n",
    "#     market_name = str.lower(market_name)\n",
    "    coverage_for_market_name = coverage[coverage.location_name.isin(market_name)]\n",
    "    return(coverage_for_market_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_distance(group, clusters_centroid):\n",
    "    empty_list = []\n",
    "    loc1 = clusters_centroid\n",
    "#     print(loc1)\n",
    "    for index, i in group.iterrows():\n",
    "        loc2 = (float(i['lat']),float(i['lon']))\n",
    "#         print(loc2)\n",
    "        empty_list.append(haversine(loc1,loc2,unit=Unit.MILES))\n",
    "    return(empty_list)\n",
    "\n",
    "def dist_from_centroid(group, centroid):\n",
    "    empty_list = []\n",
    "    for index, each in group.iterrows(): \n",
    "        empty_list.append(haversine(centroid, (each['lat'],each['lon'] ), unit='mi'))\n",
    "    return(empty_list)\n",
    "\n",
    "def popu_in_30_mins(s_df):\n",
    "    # This function gets all zip codes within 30mins driving distance of each zip and sums the population.\n",
    "    empty_list = []\n",
    "    for index, each in s_df.iterrows():\n",
    "    #     print(each.cust_zip)\n",
    "        demand_within_30mins = 0\n",
    "        for index, row in s_df.iterrows():\n",
    "    #         print(analysis(each.Latitude,each.Longitude, row.Latitude,row.Longitude))\n",
    "            if analysis(each.lat,each.lon, row.lat,row.lon)[1] <= 30.0:\n",
    "    #             print(analysis( each.Longitude,each.Latitude,  row.Longitude,row.Latitude)[1])\n",
    "    #             print(each.claim_volume)\n",
    "                demand_within_30mins = demand_within_30mins+row.Population\n",
    "    #             print(demand_within_30mins)\n",
    "    #     print(demand_within_30mins)\n",
    "        empty_list.append(demand_within_30mins)\n",
    "    return(empty_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_clust_centroids(model, dataset, level, cluster_number, clusters_centroids, clusters_radii):\n",
    "    if level == 1:\n",
    "        clusters_centroids=dict()\n",
    "        clusters_radii= dict()        \n",
    "    for cluster in list(range(model.n_clusters)):\n",
    "#         print(cluster)\n",
    "        if level == 1:\n",
    "            key = str(cluster)\n",
    "        else:\n",
    "            key = str(cluster_number + cluster/10)\n",
    "#         print(key)\n",
    "        clusters_centroids[key]=list(zip(model.cluster_centers_[:, 0],model.cluster_centers_[:,1]))[cluster]\n",
    "        clusters_radii[key] = max([haversine(i,clusters_centroids[key]) for i in list(zip(dataset[dataset.assigned_clusters == cluster]['lat'],dataset[dataset.assigned_clusters == cluster]['lon']))])\n",
    "#         print(clusters_centroids)\n",
    "    return(clusters_centroids,clusters_radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_constraint_kmeans(num_of_clusters, size_min, size_max, df):\n",
    "    clf = KMeansConstrained(\n",
    "    n_clusters=num_of_clusters,\n",
    "    size_min=size_min,\n",
    "    size_max=size_max,\n",
    "    random_state=0)\n",
    "    \n",
    "    return(clf.fit_predict(df[['lat','lon']]), clf)\n",
    "\n",
    "def apply_kmeans(num_of_clusters, df):\n",
    "    kmeans=KMeans(n_clusters=num_of_clusters, init='k-means++',random_state=0).fit(df[['lat','lon']])\n",
    "    return(kmeans.fit_predict(df[['lat','lon']]), kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(lat1, long1, lat2, long2):\n",
    "#     This function gets time taken to traven and distance between two points using OSRM package\n",
    "# The server on ip 100.70.175.6 has to be started before executing code below. Please contact Suresh to turn it on. \n",
    "#     time.sleep(1)\n",
    "    url = 'http://ra.osrm.mld.dsc.npr.aws.asurion.net:5000/route/v1/driving/{},{};{},{}'\n",
    "#     url = 'http://100.70.175.6:5000/route/v1/driving/{},{};{},{}'\n",
    "    r = requests.get(url.format(long1,lat1,long2,lat2)).text\n",
    "    data = json.loads(r)\n",
    "    try:\n",
    "        distance = round(data[\"routes\"][0][\"distance\"]*0.621371/1000, 1)\n",
    "        duration = round(data[\"routes\"][0][\"duration\"]/60, 1)\n",
    "        return([distance,duration])\n",
    "    except KeyError:\n",
    "        return([-1.0,-1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_df = gpd.read_file('C:/Users/ruta.deshmukh.NEW_STERLING/Desktop/All projects/MA_coverage/python notebooks/Archives/zip_level_shape_files/cb_2018_us_zcta510_500k.shp')\n",
    "zip_df['ZCTA5CE10'] = zip_df['ZCTA5CE10'].astype(str)\n",
    "\n",
    "def initialize_map(lat, lon, coverage):\n",
    "    m = folium.Map(location=[lat,lon], zoom_start=8, overlay=True)\n",
    "    zip_df_market = zip_df[zip_df.ZCTA5CE10.isin(coverage)]\n",
    "    fg = folium.map.FeatureGroup('coverage').add_to(m)\n",
    "    for _, r in zip_df_market.iterrows():\n",
    "            # Without simplifying the representation of each borough,\n",
    "            # the map might not be displayed\n",
    "        sim_geo = gpd.GeoSeries(r['geometry']).simplify(tolerance=0.001)\n",
    "        geo_j = sim_geo.to_json()\n",
    "        geo_j = folium.GeoJson(data=geo_j,\n",
    "                                   style_function=lambda x: {'fillColor': 'orange'}, name = 'coverage')\n",
    "        folium.Popup('coverage').add_to(geo_j)\n",
    "        fg.add_child(geo_j)\n",
    "    return(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://100.70.180.199:8080/search'\n",
    "\n",
    "def geocode_address(row):\n",
    "    params = {\n",
    "        'street': row.addr_line_1,\n",
    "        'city': row.address_city,\n",
    "        'state': row.addr_state,\n",
    "        'postalcode': row.cust_zip\n",
    "    }\n",
    "    # print(params)\n",
    "    res = requests.get(url, params=params)\n",
    "    if res and res.json():\n",
    "#         print('used adre, city, state')\n",
    "        return [res.json()[0]['lat'], res.json()[0]['lon']]\n",
    "\n",
    "#skipping city from parameters increases wrong cordinate rates\n",
    "#     params = {\n",
    "#         'street': row.addr_line_1,\n",
    "#         'state': row.addr_state,\n",
    "#         'postalcode': row.cust_zip\n",
    "#     }\n",
    "#     res = requests.get(url, params=params)\n",
    "#     if res and res.json():\n",
    "# #         print('street, state')\n",
    "#         return [res.json()[0]['lat'], res.json()[0]['lon']]\n",
    "    \n",
    "    params = {\n",
    "        'city': row.address_city,\n",
    "        'state': row.addr_state,\n",
    "        'postalcode': row.cust_zip\n",
    "    }\n",
    "    res = requests.get(url, params=params)\n",
    "    if res and res.json():\n",
    "#         print('city, state')\n",
    "        return [res.json()[0]['lat'], res.json()[0]['lon']]\n",
    "\n",
    "    params = {\n",
    "        'street': row.addr_line_1,\n",
    "        'city': row.address_city,\n",
    "        'state': row.addr_state\n",
    "    }\n",
    "    res = requests.get(url, params=params)\n",
    "    if res and res.json():\n",
    "#         print('city, state')\n",
    "        return [res.json()[0]['lat'], res.json()[0]['lon']]\n",
    "    else:\n",
    "        return 'error'\n",
    "\n",
    "def geocode_zipcode(row):\n",
    "    params = {\n",
    "        'postalcode': row.cust_zip\n",
    "    }\n",
    "    # print(params)\n",
    "    res = requests.get(url, params=params)\n",
    "    if res and res.json():\n",
    "#         print('used adre, city, state')\n",
    "        return [res.json()[0]['lat'], res.json()[0]['lon']]\n",
    "    else:\n",
    "        return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_centermost_point(cluster):\n",
    "#     centroid = (MultiPoint(cluster).centroid.x, MultiPoint(cluster).centroid.y)\n",
    "#     centermost_point = min(cluster, key=lambda point: great_circle(point, centroid).m)\n",
    "#     centermost_point[0] = float(centermost_point[0])\n",
    "#     centermost_point[1] = float(centermost_point[1])\n",
    "# #     print(tuple(centermost_point))\n",
    "#     return tuple(centermost_point)\n",
    "# centermost_points = clusters.map(get_centermost_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elbow_point(min_range, max_range, dataset):\n",
    "    Sum_of_squared_distances = []\n",
    "    K = range(1,10)\n",
    "    for num_clusters in K :\n",
    "        kmeans = KMeans(n_clusters=num_clusters)\n",
    "        kmeans.fit(dataset)\n",
    "        Sum_of_squared_distances.append([num_clusters, kmeans.inertia_])\n",
    "\n",
    "    Sum_of_squared_distances = pd.DataFrame(Sum_of_squared_distances, columns = ['num_of_clusters','sse'])\n",
    "#     print(Sum_of_squared_distances)\n",
    "    kn = KneeLocator(Sum_of_squared_distances.num_of_clusters, Sum_of_squared_distances.sse, curve='convex', direction='decreasing')\n",
    "    return(kn.knee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Loading coverage and historical service job volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get demand and coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = get_demand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully read coverage per market\n"
     ]
    }
   ],
   "source": [
    "coverage = get_market_coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['atlanta', 'portland', 'rochester',\n",
       "       'asurion major appliance repair', 'raleigh-oem', 'boston',\n",
       "       'cleveland-oem', 'asurion major appliance la', 'minneapolis-oem',\n",
       "       'detroit-oem', 'long island west', 'riverside-oem',\n",
       "       'asurion repair services', 'atlanta-oem', 'odessa-oem',\n",
       "       'fort lauderdale', 'jacksonville', 'syracuse', 'ocala', 'orlando',\n",
       "       'chicago-oem', 'new orleans-oem', 'saint louis-oem',\n",
       "       'alexandria-oem', 'indianapolis-oem', 'daytona', 'fort myers',\n",
       "       'jupiter', 'san jose-oem', 'inactive', 'los angeles-oem',\n",
       "       'long island-oem', 'denver-oem', 'houston-oem', 'seattle',\n",
       "       'tallahassee', 'dallas-oem', 'kansas city-oem', 'columbus oh-oem',\n",
       "       'des moines-oem', 'kansas city', 'dallas', 'alexandria',\n",
       "       'pittsburgh-oem', 'nashville-oem', 'louisville-oem',\n",
       "       'palm springs', 'sacramento-oem', 'miami', 'charleston-oem',\n",
       "       'cleveland', 'san diego-oem', 'san antonio-oem',\n",
       "       'long island east', 'pittsburgh', 'long beach-oem', 'buffalo',\n",
       "       'grand rapids', 'memphis-oem', 'orlando-oem', 'tampa',\n",
       "       'chattanooga', 'oklahoma city-oem'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage.location_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully read coverage per market\n"
     ]
    }
   ],
   "source": [
    "coverage_orlando = filter_market_coverage(['orlando','orlando-oem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_orlando.coverage_zip_code.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_market = demand[demand.name.isin(['ORLANDO-OEM','ORLANDO'])]\n",
    "demand_market = demand_market[['service_order_id','service_order_number','service_job_id','crm_number','service_job_number','service_job_date','addr_line_1', 'address_city', 'addr_state', 'addr_zip_code', 'name','cust_zip']].drop_duplicates()\n",
    "demand_market = demand_market.groupby(['service_order_id','service_order_number','service_job_id','service_job_date'])[['addr_line_1','address_city','addr_state','cust_zip']].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand_market = pd.merge(demand_market,bookings, on = 'service_job_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_market['cust_adr_lat_lon'] = demand_market.apply(geocode_address, axis = 1)\n",
    "demand_market[demand_market.cust_adr_lat_lon == 'error'].shape\n",
    "demand_market = demand_market[demand_market.cust_adr_lat_lon != 'error']\n",
    "demand_market['lat'] = demand_market['cust_adr_lat_lon'].apply(lambda x: x[0])\n",
    "demand_market['lon'] = demand_market['cust_adr_lat_lon'].apply(lambda x: x[1])\n",
    "demand_market[['lat','lon']] = demand_market[['lat','lon']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand_market = pd.read_csv('orlando_dataset.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting tech home locations \n",
    "# tech_locations= pd.read_excel('cleveland_tech_home_locations.xlsx')\n",
    "tech_locations = pd.read_excel('C:/Users/ruta.deshmukh.NEW_STERLING/Desktop/All projects/MA_coverage/tech_zone_coverage/Copy of Hercules Click.xlsx')\n",
    "tech_locations = tech_locations[(tech_locations['Click Market'].isin(['ORLANDO'])) & (tech_locations['Status'] == 'Production')]\n",
    "tech_locations['Click Address'] =tech_locations['Click Address'].astype(str)\n",
    "tech_locations['Click Address'] =tech_locations.apply(lambda x: np.where(x['Click Address']== 'nan', x['Home Address'],x['Click Address']), axis = 1)\n",
    "tech_locations['Click Address'] =tech_locations['Click Address'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_locations['addr_line_1'] = tech_locations['Click Address'].apply(lambda x: x.split(',')[0])\n",
    "tech_locations['address_city'] = tech_locations['Click Address'].apply(lambda x: x.split(',')[1])\n",
    "tech_locations['addr_state'] = tech_locations['Click Address'].apply(lambda x: x.split(',')[-1][0:3])\n",
    "tech_locations['cust_zip'] = tech_locations['Click Address'].apply(lambda x: x.split(',')[-1][-5:])\n",
    "\n",
    "tech_locations['adr_lat_lon'] = tech_locations.apply(geocode_address, axis = 1)\n",
    "\n",
    "tech_locations['Skill'] = ''\n",
    "tech_locations['adr_lat_lon'] = tech_locations.apply(lambda x: np.where(x.adr_lat_lon == 'error',geocode_zipcode(x), x.adr_lat_lon), axis = 1)\n",
    "# tech_locations['lat'] = tech_locations['adr_lat_lon'].apply(lambda x: x[0])\n",
    "# tech_locations['lon'] = tech_locations['adr_lat_lon'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_techs = tech_locations.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_techs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand_market['service_job_date'] = pd.to_datetime(demand_market['service_job_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Applying Dbscan to identify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import great_circle\n",
    "from shapely.geometry import MultiPoint\n",
    "# df = pd.read_csv(demand_orlando'summer-travel-gps-full.csv')\n",
    "coords = demand_market[['lat', 'lon']].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 8\n"
     ]
    }
   ],
   "source": [
    "# Higher value of min_samples results in more outliers\n",
    "\n",
    "miles_per_radian = 3958.7613\n",
    "epsilon = 5 / miles_per_radian\n",
    "db = DBSCAN(eps=epsilon, min_samples=80, algorithm='ball_tree', metric='haversine').fit(np.radians(coords))\n",
    "cluster_labels = db.labels_\n",
    "num_clusters = len(set(cluster_labels))\n",
    "clusters = pd.Series([coords[cluster_labels == n] for n in list(set(cluster_labels))])\n",
    "print('Number of clusters: {}'.format(num_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_market['assigned_clusters'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_market_nooutliers = demand_market[demand_market['assigned_clusters'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_market_nooutliers[['lat', 'lon']] = demand_market_nooutliers[['lat', 'lon']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimum number level 1 clusters in dataset using elbow point\n",
    "number_of_clusters_level1 = get_elbow_point(1,15,demand_market_nooutliers[['lat','lon']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Apply level 1 clustering using kmeans. \n",
    "#### This step identifies high level clusters by finding elbow curve point in range 0 to15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_market_nooutliers['assigned_clusters'], kmeans_clf = apply_kmeans(number_of_clusters_level1,demand_market_nooutliers)\n",
    "clusters_centroids_kmeans = {}\n",
    "clusters_radii_kmeans = {}\n",
    "clusters_centroids_kmeans, clusters_radii_kmeans = determine_clust_centroids(kmeans_clf, demand_market_nooutliers, 1, 1, clusters_centroids_kmeans ,clusters_radii_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_market_nooutliers['color_level1'] = color_scheme.assign_color(demand_market_nooutliers.assigned_clusters, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_stats(dataset, centroid_dict, number_of_techs):\n",
    "    tablular_analysis_clusters = pd.DataFrame()\n",
    "    for rec in dataset.assigned_clusters.unique():\n",
    "        Cluster_df = dataset[dataset.assigned_clusters == rec]\n",
    "        Cluster_df['distance_from_centroid'] = dist_from_centroid(Cluster_df, centroid_dict[str(rec)])\n",
    "        tablular_analysis = pd.DataFrame()\n",
    "        tablular_analysis['assigned_clusters_level1'] = Cluster_df.assigned_clusters.unique()\n",
    "        tablular_analysis['cluster number'] = Cluster_df.assigned_clusters.unique()\n",
    "        tablular_analysis['claim volume in cluster'] = Cluster_df.shape[0]\n",
    "        tablular_analysis['% claims in cluster'] = round((Cluster_df.shape[0]/dataset.shape[0])*100)\n",
    "        tablular_analysis['number_of_techs'] = round((tablular_analysis['% claims in cluster']*number_of_techs)/100)\n",
    "        tablular_analysis['weighted avg driving distance'] = round(average( Cluster_df['distance_from_centroid']),2)\n",
    "        tablular_analysis['farthest point in cluster'] = Cluster_df[Cluster_df.distance_from_centroid == Cluster_df.distance_from_centroid.max()]['distance_from_centroid'].values[0]\n",
    "        tablular_analysis_clusters = tablular_analysis_clusters.append(tablular_analysis)\n",
    "    return(tablular_analysis_clusters)\n",
    "\n",
    "level1_clustering_stats = cluster_stats(demand_market_nooutliers, clusters_centroids_kmeans, number_of_techs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_market_nooutliers.cust_zip.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Apply level 2 clustering using constraint kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_market_nooutliers['assigned_clusters_level1'] = demand_market_nooutliers['assigned_clusters']\n",
    "df_level2_clusters = pd.DataFrame()\n",
    "tabular_analysis_level2 = pd.DataFrame()\n",
    "for index, each in level1_clustering_stats.iterrows():\n",
    "    if each.number_of_techs >1:\n",
    "#         print(level2_cluster_num)\n",
    "        df = demand_market_nooutliers[demand_market_nooutliers.assigned_clusters_level1 == each['assigned_clusters_level1']]\n",
    "        max_size = round(df.shape[0]/each.number_of_techs)+10\n",
    "        min_size = 10\n",
    "        num_of_techs = each.number_of_techs.astype(int)\n",
    "        cluster_number = df.assigned_clusters_level1.unique()[0]\n",
    "        \n",
    "        df['assigned_clusters'], clf = apply_constraint_kmeans(num_of_techs, min_size,max_size,df )\n",
    "        clusters_centroids_constraint_kmeans, clusters_radii_constraint_kmeans = determine_clust_centroids(clf, df, 2, cluster_number, clusters_centroids_kmeans, clusters_radii_kmeans)\n",
    "        \n",
    "        #Change cluster naming after determining centroids\n",
    "        df['assigned_clusters'] = df['assigned_clusters_level1'] + df['assigned_clusters']/10\n",
    "        \n",
    "#         append to tabular_analysis_level2 df\n",
    "        tabular_analysis = cluster_stats(df, clusters_centroids_constraint_kmeans,1)\n",
    "        tabular_analysis['cluster_level'] = 2\n",
    "        tabular_analysis_level2 = tabular_analysis_level2.append(tabular_analysis)\n",
    "        df_level2_clusters = df_level2_clusters.append(df)\n",
    "        \n",
    "    #if only 1 tech is assigned to level 1 cluster then skip level 2 clustering\n",
    "    elif each.number_of_techs ==1:\n",
    "        df = demand_market_nooutliers[demand_market_nooutliers.assigned_clusters_level1 == each['assigned_clusters_level1']]\n",
    "        df['assigned_clusters'] = df['assigned_clusters_level1']\n",
    "        \n",
    "        tabular_analysis = level1_clustering_stats[level1_clustering_stats.assigned_clusters_level1 == each.assigned_clusters_level1]\n",
    "        tabular_analysis['cluster_level'] = 1\n",
    "        tabular_analysis_level2 = tabular_analysis_level2.append(tabular_analysis)\n",
    "        df_level2_clusters = df_level2_clusters.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_analysis_level2['centroid_lat'] = tabular_analysis_level2.apply(lambda x: clusters_centroids_constraint_kmeans[str(x.assigned_clusters_level1)][0] if x.cluster_level == 2 else clusters_centroids_kmeans[str(int(x.assigned_clusters_level1))][0] , axis = 1)\n",
    "tabular_analysis_level2['centroid_lon'] = tabular_analysis_level2.apply(lambda x: clusters_centroids_constraint_kmeans[str(x.assigned_clusters_level1)][1] if x.cluster_level == 2 else clusters_centroids_kmeans[str(int(x.assigned_clusters_level1))][1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_analysis_level2['% claims in cluster'] = tabular_analysis_level2['claim volume in cluster']/tabular_analysis_level2['claim volume in cluster'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lat'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-897078ad46fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0massigned_techs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtabular_analysis_level2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtech_locations_bkp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcentroid_lat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcentroid_lon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtech_indx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-edfc008e86b4>\u001b[0m in \u001b[0;36mfunction_distance\u001b[1;34m(group, clusters_centroid)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#     print(loc1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mloc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#         print(loc2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mempty_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhaversine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloc2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mUnit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMILES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lat'"
     ]
    }
   ],
   "source": [
    "tech_locations_bkp = tech_locations.reset_index()\n",
    "assigned_techs = pd.DataFrame()\n",
    "for index, each in tabular_analysis_level2.iterrows():\n",
    "    l = function_distance(tech_locations_bkp,(each.centroid_lat, each.centroid_lon))\n",
    "    if len(l)>0:\n",
    "        tech_indx = l.index(min(l))\n",
    "        assigned_techs = assigned_techs.append([tech_locations_bkp[tech_locations_bkp.index==tech_indx][['Name','Home Address']]])\n",
    "        tech_locations_bkp = tech_locations_bkp.drop(index = tech_indx).reset_index(drop=True)\n",
    "    else:\n",
    "        assigned_techs.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_analysis_level2['assigned_tech_name'] = assigned_techs['Name'].values\n",
    "tabular_analysis_level2['Home Address'] = assigned_techs['Home Address'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mapping():\n",
    "color_schemes = pd.read_csv('C:/Users/ruta.deshmukh.NEW_STERLING/Desktop/All projects/MA_coverage/tech_zone_coverage/color_list_folium.csv', sep = '|')\n",
    "color_schemes['cluster_num'] = np.arange(0.0, 11.0, 0.1)[:-3]\n",
    "color_schemes['cluster_num'] = color_schemes['cluster_num'].apply(lambda x: round(x, 1))\n",
    "# color_schemes['cluster_num'] = color_schemes['cluster_num'].astype(str)\n",
    "mapping = dict(color_schemes[['cluster_num', 'color']].values)\n",
    "#     return mapping\n",
    "\n",
    "def assign_color(col, mapping):\n",
    "    color_selected = col.map(mapping)\n",
    "    return color_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_level2_clusters['color_level2'] = assign_color(df_level2_clusters.assigned_clusters, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Plotting clusters on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m_level1 = initialize_map(demand_market_nooutliers.lat.iloc[0],demand_market_nooutliers.lon.iloc[0], coverage_orlando.coverage_zip_code)\n",
    "HeatMap(demand_market[['lat','lon']], name = 'Claim Volume').add_to(m_level1)\n",
    "\n",
    "fg_clusters = folium.map.FeatureGroup('level1_clusters').add_to(m_level1)\n",
    "for lt, ln, color in zip(demand_market_nooutliers.lat, demand_market_nooutliers.lon, demand_market_nooutliers.color_level1):\n",
    "    cm = folium.CircleMarker(location=[lt, ln],\n",
    "                            radius = 6,\n",
    "#                             popup=str(el)+\" m\",\n",
    "                            fill=True, # Set fill to True\n",
    "                            fill_color=color,\n",
    "                            color = color,\n",
    "                            fill_opacity=0.7,\n",
    "                            line_opacity=0.7,\n",
    "                            name = 'Clusters',\n",
    "                            control=True)\n",
    "    fg_clusters.add_child(cm)\n",
    "\n",
    "fg_techs = folium.map.FeatureGroup('Tech Assigned Locations').add_to(m_level1)\n",
    "for lt, ln, skill, tech_name in zip(tabular_analysis_level2.centroid_lat, tabular_analysis_level2.centroid_lon, tech_locations.Skill, tabular_analysis_level2.assigned_tech_name):\n",
    "#     print(tech_name)\n",
    "    if skill == 'senior':\n",
    "        cm = folium.Marker(location=[lt, ln],\n",
    "                           popup = tech_name,\n",
    "                           icon=folium.Icon(color='blue', icon='male', prefix='fa'))\n",
    "    else:\n",
    "        cm = folium.Marker(location=[lt, ln],\n",
    "                            popup = tech_name,\n",
    "                           icon=folium.Icon(color='lightgray', icon='male', prefix='fa'))\n",
    "    fg_techs.add_child(cm)\n",
    "    \n",
    "for each in df_level2_clusters.assigned_clusters_level1.unique():\n",
    "    plot_df = df_level2_clusters[df_level2_clusters.assigned_clusters_level1 == each]\n",
    "    fg_clusters = folium.map.FeatureGroup('level2_cluster{}'.format(plot_df.assigned_clusters_level1.values[0])).add_to(m_level1)\n",
    "    for lt, ln, color in zip(plot_df.lat, plot_df.lon, plot_df.color_level2):\n",
    "        cm = folium.CircleMarker(location=[lt, ln],\n",
    "                                radius = 6,\n",
    "    #                             popup=str(el)+\" m\",\n",
    "                                fill=True, # Set fill to True\n",
    "                                fill_color=color,\n",
    "                                color = color,\n",
    "                                fill_opacity=0.7,\n",
    "                                line_opacity=0.7,\n",
    "                                name = 'clusters',\n",
    "                                control=True)\n",
    "        fg_clusters.add_child(cm)\n",
    "        \n",
    "# Adding layer controls to select which layers to display\n",
    "folium.LayerControl().add_to(m_level1)\n",
    "\n",
    "m_level1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_level1.save('tech_assigned_7_techs.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_level2_clusters.to_csv('orlando_dataset_with_labels.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabular_analysis_level2.to_excel('cluster_stats_tampa_7_tech_assigned.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6)Avg drive time per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulations on each clusters to determine total time techs will drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_osrm(jobs, centroid_lat,centroid_long):\n",
    "#     print(centroid_lat[0], centroid_long[0])\n",
    "    sorted_locations = pd.DataFrame(data = [[centroid_lat[0],centroid_long[0],0]], columns = ['lat', 'lon', 'duration'])\n",
    "    while len(jobs)>0:\n",
    "        least_dist = [] #this will store distance of each job from last point in sorted_locations\n",
    "        for idx, each in jobs.iterrows():\n",
    "            # if len(jobs) is 6 then get travel duration between centroid and each of the 6 random jobs and find the job that is closest from centroid. Remove that job from list of jobs.\n",
    "            # if len(jobs) is less than 6 then get the travel duration between last job in sorted_locations_list and each of the remaining random jobs. Find the job that is closest and remove the job from job list.\n",
    "            travel_distance_duration = analysis(sorted_locations[-1:]['lat'].values[0],sorted_locations[-1:]['lon'].values[0],each.lat,each.lon)\n",
    "            least_dist.append([each.lat, each.lon,travel_distance_duration[0],travel_distance_duration[1]])\n",
    "        least_dist_df =pd.DataFrame(least_dist, columns = ['lat', 'lon', 'distance' , 'duration'])\n",
    "        sorted_locations = sorted_locations.append(least_dist_df[least_dist_df.duration == least_dist_df.duration.min()])\n",
    "#         print(sorted_locations)\n",
    "        jobs = least_dist_df[least_dist_df.duration != least_dist_df.duration.min()][['lat','lon']]\n",
    "    return([round(sorted_locations.distance.sum(),1), round(sorted_locations.duration[1:].sum(),1)]) #    return(round(sorted_zips.duration.sum()/60,1)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate current setup metrics\n",
    "current_route_metrics = []\n",
    "def current_route_metrics_fun(group):\n",
    "    total_travel_duration_dist=[]\n",
    "    for each_expert in tech_locations.Name.drop_duplicates().values:\n",
    "        jobs = group[group.expert_name.str.lower() == str.lower(each_expert)]\n",
    "#         print(jobs)\n",
    "        if len(jobs)>1:\n",
    "            starting_location = (tech_locations[tech_locations.Name.str.lower() == str.lower(each_expert)][['lat','lon']])\n",
    "#             print(starting_location)\n",
    "            dur_dist = get_path_osrm(jobs, starting_location.lat.values, starting_location.lon.values)\n",
    "            current_route_metrics.append([str.lower(each_expert),group.ActionDay.values[0], dur_dist[0], dur_dist[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulations(demand_df, centroid_lat, centroid_long):\n",
    "    total_travel_duration_dist = []\n",
    "    for i in range(1000):\n",
    "#         jobs = random.choices(demand_df.cust_zip.to_list(),k=6)\n",
    "        #pick 6 random customer home locations where we have recieved a job\n",
    "        jobs= demand_df[['lat','lon']].sample(n=6,replace=False)\n",
    "        \n",
    "        # get_path_osrm_duration() returns total time taken by tech to travel between 6 locations. \n",
    "        # For each day we find the total time taken to travel and append it to total_travel_duration list.\n",
    "        total_travel_duration_dist.append(get_path_osrm(jobs, centroid_lat, centroid_long))\n",
    "    total_travel_duration_dist = pd.DataFrame(total_travel_duration_dist,columns = ['duration', 'distance'] )\n",
    "    #Following step returns the percentage cases where travel time was more than 120 mins/2hours. we could add more mtrics here like average time taken to tavel in this cluster.\n",
    "    return([(total_travel_duration_dist[total_travel_duration_dist.duration >120].shape[0]/total_travel_duration_dist.shape[0])*100,round(total_travel_duration_dist.duration.mean()), round(total_travel_duration_dist.distance.mean())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#proposed clustering driving distance and duration\n",
    "travel_metrics_all = []\n",
    "for each in tabular_analysis_level2.assigned_clusters_level1:\n",
    "    # tabular_analysis_level2 has all the level_2 cluster details like which tech covers the area. Running simulations and adding a flag to know which clusters are underperforming.\n",
    "    travel_metrics = run_simulations(df_level2_clusters[df_level2_clusters.assigned_clusters == each], tabular_analysis_level2[tabular_analysis_level2.assigned_clusters_level1 == each]['centroid_lat'], tabular_analysis_level2[tabular_analysis_level2.assigned_clusters_level1 == each]['centroid_lon'])\n",
    "#     travel_metrics = run_simulations(df_level2_clusters[df_level2_clusters.assigned_clusters == each], tabular_analysis_level2[tabular_analysis_level2.assigned_clusters_level1 == each]['centroid_lat'], tabular_analysis_level2[tabular_analysis_level2.assigned_clusters_level1 == each]['centroid_lon'])\n",
    "    travel_metrics_all.append([each,travel_metrics])\n",
    "\n",
    "#this column is the percentage of days when total drive time for techs was more than 2hours.\n",
    "# tabular_analysis_level2['perc_days_w_2hours_driving_osrm'] = probab_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proposed clustering driving distance and duration. Following are the durations and distances per cluster. Starting distance is cluster centroid\n",
    "travel_metrics_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate current setup metrics. Following are the durations and distances for current coverage. Starting location is tech's home\n",
    "current_route_metrics = []\n",
    "for each_expert in tech_locations.Name.drop_duplicates().values:\n",
    "    starting_location = (tech_locations[tech_locations.Name.str.lower() == str.lower(each_expert)][['lat','lon']])\n",
    "    dur_dist = run_simulations(demand_market, starting_location.lat.values, starting_location.lon.values)\n",
    "    current_route_metrics.append([str.lower(each_expert), dur_dist[0], dur_dist[1], dur_dist[2], dur_dist[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_route_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign nearest centroid for each outlier point\n",
    "assign_centroids = tabular_analysis_level2[['centroid_lat','centroid_lon','assigned_clusters_level1']]\n",
    "assign_centroids[['centroid_lat','centroid_lon']] = assign_centroids[['centroid_lat','centroid_lon']].astype(float)\n",
    "assign_centroids = assign_centroids.reset_index()\n",
    "def nearest_centriod(point):\n",
    "#     print(point['lat'])\n",
    "    job_lat = float(point['lat'])\n",
    "    job_lon = float(point['lon'])\n",
    "    \n",
    "    distances = assign_centroids.apply(lambda row: haversine((job_lat, job_lon), (row['centroid_lat'], row['centroid_lon']), unit=Unit.MILES), \n",
    "        axis=1)\n",
    "    return assign_centroids.loc[distances.idxmin(), 'assigned_clusters_level1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_market['assigned_level2_clusters']  =demand_market.apply(lambda x: nearest_centriod(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_market =demand_market.merge(assign_centroids, left_on = 'assigned_level2_clusters',right_on = 'assigned_clusters_level1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THD jobs in cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_thd_demand = \"\"\"\n",
    "select distinct install_base_id,\n",
    "    claim.sr_num,\n",
    "   claim.claim_create_tm,\n",
    "   cust.cust_zip,\n",
    "   cust.cust_addr1,\n",
    "   cust.cust_city,\n",
    "   cust.cust_state\n",
    "   from \n",
    "   hive.l3_retail.scm_claim claim \n",
    "\tinner join hive.l3_retail.scm_product_dim pd on claim.dw_product_id =  pd.dw_product_id \n",
    "\tinner join hive.l3_retail.scm_dealer_dim dealer on dealer.dw_dealer_id = claim.dw_dealer_id\n",
    "\tinner join hive.l3_retail.scm_top_sr as top on claim.top_sr_num = top.top_sr_num \n",
    "\tinner join hive.l3_retail.scm_claim_type_dim claimtype on top.dw_claim_type_id = claimtype.dw_claim_type_id \n",
    "    inner join hive.l3_retail.scm_customer_dim cust on cust.dw_customer_id = claim.dw_customer_id\n",
    "    INNER JOIN hive.l3_retail.scm_service_job sj on sj.dw_top_sr_id = top.dw_top_sr_id\n",
    "where dealer.dealer_name = 'THE HOME DEPOT USA INC'\n",
    "and cast(claim.claim_create_tm as date)  between date('2021-01-01') and date('2021-12-31')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presto_edp = atlas.Presto(environment = \"presto://{}:{}@edp-workbench-adhoc.edp.prd.aws.asurion.net:18443/hive\").connect()\n",
    "\n",
    "thd_demand_df = pd.read_sql(sql_thd_demand, presto_edp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thd_demand_df.cust_zip[thd_demand_df.cust_zip.isin(coverage_orlando.coverage_zip_code.unique())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thd_demand_df.cust_zip[thd_demand_df.cust_zip.isin(demand_market_nooutliers.cust_zip.astype(str).unique())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.790844898953007"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6496/8214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "thd_demand_df.columns = ['install_base_id', 'sr_num', 'claim_create_tm', 'cust_zip',\n",
    "       'addr_line_1', 'address_city', 'addr_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-cf7bad0e51a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mthd_demand_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cust_lat_lon'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthd_demand_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeocode_zipcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mthd_demand_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lat'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthd_demand_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cust_lat_lon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mthd_demand_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lon'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthd_demand_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cust_lat_lon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8739\u001b[0m         )\n\u001b[1;32m-> 8740\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-fed413a5a2f0>\u001b[0m in \u001b[0;36mgeocode_zipcode\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     52\u001b[0m     }\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# print(params)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m#         print('used adre, city, state')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    527\u001b[0m         }\n\u001b[0;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m                 )\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m             )\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                 \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;31m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"user-agent\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"User-Agent\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1242\u001b[0m                 encode_chunked=False):\n\u001b[0;32m   1243\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1288\u001b[0m             \u001b[1;31m# default charset of iso-8859-1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1289\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1290\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"\\r\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    964\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 170\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             )\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "thd_demand_df['cust_lat_lon'] = thd_demand_df.apply(geocode_zipcode, axis = 1)\n",
    "thd_demand_df['lat'] = thd_demand_df['cust_lat_lon'].apply(lambda x: x[0])\n",
    "thd_demand_df['lon'] = thd_demand_df['cust_lat_lon'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m_level1 = initialize_map(thd_demand_df.lat.iloc[0],thd_demand_df.lon.iloc[0], coverage_orlando.coverage_zip_code)\n",
    "HeatMap(thd_demand_df[['lat','lon']], name = 'Claim Volume').add_to(m_level1)\n",
    "\n",
    "fg_clusters = folium.map.FeatureGroup('level1_clusters').add_to(m_level1)\n",
    "for lt, ln, color in zip(demand_market_nooutliers.lat, demand_market_nooutliers.lon, demand_market_nooutliers.color_level1):\n",
    "    cm = folium.CircleMarker(location=[lt, ln],\n",
    "                            radius = 6,\n",
    "#                             popup=str(el)+\" m\",\n",
    "                            fill=True, # Set fill to True\n",
    "                            fill_color=color,\n",
    "                            color = color,\n",
    "                            fill_opacity=0.7,\n",
    "                            line_opacity=0.7,\n",
    "                            name = 'Clusters',\n",
    "                            control=True)\n",
    "    fg_clusters.add_child(cm)\n",
    "\n",
    "fg_techs = folium.map.FeatureGroup('Tech Assigned Locations').add_to(m_level1)\n",
    "for lt, ln, skill, tech_name in zip(tabular_analysis_level2.centroid_lat, tabular_analysis_level2.centroid_lon, tech_locations.Skill, tabular_analysis_level2.assigned_tech_name):\n",
    "#     print(tech_name)\n",
    "    if skill == 'senior':\n",
    "        cm = folium.Marker(location=[lt, ln],\n",
    "                           popup = tech_name,\n",
    "                           icon=folium.Icon(color='blue', icon='male', prefix='fa'))\n",
    "    else:\n",
    "        cm = folium.Marker(location=[lt, ln],\n",
    "                            popup = tech_name,\n",
    "                           icon=folium.Icon(color='lightgray', icon='male', prefix='fa'))\n",
    "    fg_techs.add_child(cm)\n",
    "    \n",
    "for each in df_level2_clusters.assigned_clusters_level1.unique():\n",
    "    plot_df = df_level2_clusters[df_level2_clusters.assigned_clusters_level1 == each]\n",
    "    fg_clusters = folium.map.FeatureGroup('level2_cluster{}'.format(plot_df.assigned_clusters_level1.values[0])).add_to(m_level1)\n",
    "    for lt, ln, color in zip(plot_df.lat, plot_df.lon, plot_df.color_level2):\n",
    "        cm = folium.CircleMarker(location=[lt, ln],\n",
    "                                radius = 6,\n",
    "    #                             popup=str(el)+\" m\",\n",
    "                                fill=True, # Set fill to True\n",
    "                                fill_color=color,\n",
    "                                color = color,\n",
    "                                fill_opacity=0.7,\n",
    "                                line_opacity=0.7,\n",
    "                                name = 'clusters',\n",
    "                                control=True)\n",
    "        fg_clusters.add_child(cm)\n",
    "        \n",
    "# Adding layer controls to select which layers to display\n",
    "folium.LayerControl().add_to(m_level1)\n",
    "\n",
    "m_level1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) compare scheduled jobs for a day with proposed setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "presto_edp = atlas.Presto(environment = \"presto://{}:{}@edp-workbench-adhoc.edp.prd.aws.asurion.net:18443/hive\").connect()\n",
    "\n",
    "sql = \"\"\"\n",
    "\n",
    "/* Creates a dataset for visualizing and analyzing technician use\n",
    "* of Kronos and the Service Bench Field App.\n",
    "* 11/15/2021 Revert to seperate query for punch pair from Atlas.\n",
    "* EDP file is not properly ingested. Also, adding paycode to the schedule.\n",
    "* 11/8/2021 Add scheduled time as action pair\n",
    "* 11/4/2021 Adds tech on attempt logic\n",
    "* 10/27/21 Adds technician data directly\n",
    "* 10/14/21 Need to make timezone adjustment prior to defining the Action Day.\n",
    "* Placed all timezone adjustments in the SQL and removed the timezone adjustment field.\n",
    "* 10/8/21 TechID needs to be Emplid for new tech lookup table\n",
    "* 9/16/21 Time zone adjustment\n",
    "* 9/9/21 learned that punchpairs were in edp. Began adding punchpair union.\n",
    "* 8/24/21 Returned to orignal that does not filter for manufacture id = 43.\n",
    "* This will get all valid techs for 5G and SameDay. Also added service job number.\n",
    "* 8/19/21 Removed substatuscomplete imputation*/\n",
    "with technician_table as (\n",
    "with person_worker as (\n",
    "-- finds distinct job codes and job titles\n",
    "select\n",
    "jobcode\n",
    ", array_agg(job_title order by job_title asc)[1] as job_title\n",
    "from hive.rtm_analytics.l2_asurion_hrprd_dbo_asu_person_worker\n",
    "group by jobcode\n",
    ")\n",
    ", OtherDates as (\n",
    "select\n",
    "emplid\n",
    ", max(job_entry_date ) as JobEntryDate\n",
    ", max(last_hire_dt ) as LastHireDate\n",
    "from hive.rtm_analytics.l2_asurion_hrprd_dbo_asu_person_worker\n",
    "group by emplid\n",
    ")\n",
    "select distinct\n",
    "master.expert_id\n",
    ", (array_join((transform((split(master.expert_full_name,' ')), x -> concat(upper(substr(x,1,1)),substr(x,2,length(x))))),' ',' ')) as expert_name\n",
    ", master.hire_dt\n",
    ", master.rehire_dt\n",
    ", hier.lob_name\n",
    ", hier.location_descr\n",
    ", hier.eff_start_dt\n",
    ", hier.eff_end_dt\n",
    ", (array_join((transform((split(hier.supervisor_full_name,' ')), x -> concat(upper(substr(x,1,1)),substr(x,2,length(x))))),' ',' ')) as supervisor_name\n",
    ", (array_join((transform((split(hier.manager_full_name,' ')), x -> concat(upper(substr(x,1,1)),substr(x,2,length(x))))),' ',' ')) as manager_name\n",
    ", person_worker.job_title\n",
    ", otherdates.jobentrydate\n",
    ", otherdates.lasthiredate\n",
    "-- This gives a unique number per \"employee-manager-supervisor-title\" record. This is used in Power BI to connect job and visits tables on technician\n",
    ", concat(master.expert_id,hier.supervisor_id, hier.manager_id, hier.jobcode) as unique_identifier\n",
    "from hive.rtm_analytics.l3_asurion_whole_home_expert_master master\n",
    "join hive.rtm_analytics.l3_asurion_whole_home_expert_hierarchy hier\n",
    "on hier.expert_id = master.expert_id\n",
    "left join person_worker\n",
    "on upper(person_worker.jobcode) = upper(hier.jobcode)\n",
    "left join otherdates\n",
    "on otherdates.emplid=master.expert_id\n",
    "where hier.jobcode in\n",
    "('crn1120', 'crn1161', 'crn1150', 'scn1096', 'scn1097', 'crn1149', 'crn1144', 'crn1143')\n",
    "order by master.expert_id, eff_start_dt desc\n",
    "),\n",
    "ActionTable as (\n",
    "select distinct\n",
    "--This is a technician rather than visit based analysis so removes duplication for visits.\n",
    "tech.dtl_sptech_id as Emplid,\n",
    "--coalesce(svdtl.dtl_techonattempt, svdtl.dtl_startofdaytechid, svdtl.dtl_techid) as newTechID,\n",
    "--svdtl.dtl_techid as oldTechID,\n",
    "substring(svdtl.dk_sjvisit_id,1,position('_' in svdtl.dk_sjvisit_id)-1) as SJ_ID,\n",
    "--svdtl.ddtl_visitfirstarrive,\n",
    "--upper(svdtl.dtl_techname) as TechName,\n",
    "'Visit' as ActType, --Identifies the action type for visualization. The visit in/out combinations are identified here.\n",
    "--Adds the timezone adjustment to the action times to bring them from Eastern time to local time.\n",
    "date(date_add('hour',(svgeo.inttimezoneoffsetgmc + 5),svdtl.ddtl_visitfirstarrive)) as ActionDay,\n",
    "-- (svgeo.inttimezoneoffsetgmc+5) as TimeAdjust,\n",
    "date_add('hour',(svgeo.inttimezoneoffsetgmc+5),svdtl.ddtl_visitfirstarrive) as ActionStart,\n",
    "case --When there is no depart date recorded for the visit adds 57 minutes. Median visit time imputed based on six months of visits.\n",
    "when svdtl.ddtl_visitfirstdepart is null\n",
    "then cast(date_add('hour',(svgeo.inttimezoneoffsetgmc+5),svdtl.ddtl_visitfirstarrive) as timestamp) + interval '57' minute\n",
    "else date_add('hour',(svgeo.inttimezoneoffsetgmc+5),svdtl.ddtl_visitfirstdepart)\n",
    "end as ActionFinish,\n",
    "'' as PayCode\n",
    "--,tech.dtl_techfirstname\n",
    "--,tech.dtl_techlastname\n",
    "from hive.sinewdba.d_visits_drill_to_detail as svdtl\n",
    "--Joins timezone adjustment\n",
    "left join hive.sinewdba.f_visits as sv\n",
    "on svdtl.dk_sjvisit_id = sv.dk_sjvisit_id\n",
    "left join hive.sinewdba.d_geography as svgeo\n",
    "on sv.dk_geography_id = svgeo.dk_geography_id\n",
    "--Joins Emplid\n",
    "left join hive.sinewdba.d_sp_tech as tech\n",
    "on\n",
    "cast(\n",
    "coalesce(svdtl.dtl_techonattempt, svdtl.dtl_startofdaytechid, svdtl.dtl_techid)\n",
    "as integer\n",
    ") = tech.dtl_techid\n",
    "--Filters for only valid technicians and most recent three months\n",
    "where svdtl.ddtl_visitfirstarrive >=date_add('day',-180,current_date)\n",
    "and cast(svdtl.dtl_techid as integer) >0\n",
    "and svdtl.dtl_techid <> 'UNKNOWN'\n",
    "and svdtl.ddtl_visitfirstarrive is not null\n",
    "and sv.intaccountnumberid in\n",
    "(23946,26138,35623)\n",
    "-- and lower(tech.dtl_techfirstname) = 'ernst'\n",
    "--order by svdtl.ddtl_visitfirstarrive desc\n",
    "\n",
    "\n",
    "\n",
    "/*Union to create an \"action\" data set rather than a visit dataset.\n",
    "The subsequent code identifies \"en route\" to \"arrival\" actions where available.*/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "union\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "select distinct\n",
    "tech.dtl_sptech_id as Emplid,\n",
    "substring(svdtl.dk_sjvisit_id,1,position('_' in svdtl.dk_sjvisit_id)-1) as SJ_ID,\n",
    "--upper(svdtl.dtl_techname) as TechName,\n",
    "'EnRoute' as ActType,\n",
    "date(date_add('hour',(svgeo.inttimezoneoffsetgmc + 5),svdtl.ddtl_visitfirstenroute)) as ActionDay,\n",
    "--(svgeo.inttimezoneoffsetgmc + 5) as TimeAdjust,\n",
    "date_add('hour',(svgeo.inttimezoneoffsetgmc+5),svdtl.ddtl_visitfirstenroute) as ActionStart,\n",
    "case\n",
    "--When there is no arrival date recorded for the visit adds 24 minutes.\n",
    "--Median enroute time imputed based on six months of enroute times (Feb to August 2021).\n",
    "--Future improvement should impute by market median.\n",
    "when svdtl.ddtl_visitfirstarrive is null\n",
    "then cast(date_add('hour',(svgeo.inttimezoneoffsetgmc+5),svdtl.ddtl_visitfirstenroute) as timestamp) + interval '24' minute\n",
    "else date_add('hour',(svgeo.inttimezoneoffsetgmc+5),svdtl.ddtl_visitfirstarrive)\n",
    "end as ActionFinish,\n",
    "'' as PayCode\n",
    "from hive.sinewdba.d_visits_drill_to_detail as svdtl\n",
    "left join hive.sinewdba.f_visits as sv\n",
    "on svdtl.dk_sjvisit_id = sv.dk_sjvisit_id\n",
    "left join hive.sinewdba.d_geography as svgeo\n",
    "on sv.dk_geography_id = svgeo.dk_geography_id\n",
    "left join hive.sinewdba.d_sp_tech as tech\n",
    "on\n",
    "cast(\n",
    "coalesce(svdtl.dtl_techonattempt, svdtl.dtl_startofdaytechid, svdtl.dtl_techid)\n",
    "as integer\n",
    ") = tech.dtl_techid\n",
    "where svdtl.ddtl_visitfirstenroute>=date_add('day',-180,current_date)\n",
    "and cast(svdtl.dtl_techid as integer) >0\n",
    "and svdtl.dtl_techid <> 'UNKNOWN'\n",
    "and svdtl.ddtl_visitfirstenroute is not null\n",
    "and sv.intaccountnumberid in\n",
    "(23946,26138,35623)\n",
    "/*Union to add punch pairs. Current l1 version of punchpairs.\n",
    "* Comment out Kronos file import. Vic Duggan indicated his \"Journey Team\"\n",
    "* will assist with creating an EDP version but did not provide a timeline.\n",
    "* The table references will likely change once that is available.*/\n",
    "union\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "select\n",
    "punchpair.employee_id as Emplid,\n",
    "'' as SJ_ID,\n",
    "--upper(PunchPair.employee_name) as TechName,\n",
    "'ClockInOut' as ActType,\n",
    "cast(substring(PunchPair.in_punch_date_and_time,1,10) as date) as ActionDay,\n",
    "--0 as TimeAdjust,\n",
    "cast(substring(PunchPair.in_punch_date_and_time,1,19) as timestamp) as ActionStart,\n",
    "min(cast(substring(PunchPair.out_punch_date_and_time,1,19) as timestamp)) as ActionFinish,\n",
    "'' as PayCode\n",
    "from hive.l1_asurion.flatfile_dbo_enterprise_punch_pairs as PunchPair\n",
    "where\n",
    "exists (\n",
    "select 1\n",
    "from hive.sinewdba.d_sp_tech\n",
    "where punchpair.employee_id = hive.sinewdba.d_sp_tech.dtl_sptech_id\n",
    ")\n",
    "and PunchPair.in_punch_date_and_time is not null\n",
    "and punchpair.out_punch_date_and_time is not null\n",
    "and try_cast(substring(PunchPair.in_punch_date_and_time,1,10) as date)>=date_add('day',-180,current_date)\n",
    "group by punchpair.employee_id, PunchPair.in_punch_date_and_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "union\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "select\n",
    "Schedule.personnum as Emplid,\n",
    "'' as SJ_ID,\n",
    "'SchedTime' as ActType,\n",
    "cast(substring(schedule.shiftstartdate,1,10) as date) as ActionDay,\n",
    "cast(substring(schedule.shiftstartdate,1,19) as timestamp) as ActionStart,\n",
    "cast(substring(schedule.shiftenddate,1,19) as timestamp) as ActionFinish,\n",
    "schedule.paycodename as PayCode\n",
    "from hive.l1_asurion.flatfile_dbo_bi_care_schedules as Schedule\n",
    "where\n",
    "exists (\n",
    "select 1\n",
    "from hive.sinewdba.d_sp_tech\n",
    "where schedule.personnum = hive.sinewdba.d_sp_tech.dtl_sptech_id\n",
    ")\n",
    "and schedule.shiftstartdate is not null\n",
    "and schedule.shiftenddate is not null\n",
    "and try_cast(substring(schedule.shiftstartdate,1,10) as date)>=date_add('day',-180,current_date)\n",
    "),\n",
    "techtype as (\n",
    "select\n",
    "dtl_sptech_id, array_agg(dtl_serviceprovider_id order by ddtl_lastmodified desc)[1] as SPID, array_agg(dtl_serviceprovider order by ddtl_lastmodified desc)[1] as ServProvider\n",
    "from hive.sinewdba.d_sp_tech\n",
    "WHERE\n",
    "dtl_serviceprovider_id in (\n",
    "1133787699,\n",
    "1116738095,\n",
    "--1074057588,\n",
    "--1029655484,\n",
    "1115480731\n",
    ")\n",
    "group by dtl_sptech_id\n",
    ")\n",
    "select distinct\n",
    "actiontable.*,\n",
    "technician_table.*,\n",
    "techtype.*,\n",
    "dl.name as market_location,\n",
    "cus.address_line_1 addr_line_1,\n",
    "cus.address_city,\n",
    "cus.address_province addr_state,\n",
    "cus.address_postal_code cust_zip\n",
    "from actiontable\n",
    "left join technician_table\n",
    "on technician_table.expert_id=actiontable.emplid and\n",
    "actiontable.actionday between technician_table.eff_start_dt and technician_table.eff_end_dt\n",
    "left join techtype\n",
    "on techtype.dtl_sptech_id = actiontable.emplid\n",
    "left join hive.rtm_analytics.l2_retail_odhsb_sbv5_at_service_job sj on sj.service_job_id = actiontable.SJ_ID\n",
    "left join hive.l2_retail.odhsb_sb_svbt_dispatch_zone z on sj.sj_zone_id = z.zone_id_char\n",
    "left join hive.l2_retail.odhsb_sb_svbt_dealer_location dl on z.dealer_location_id = dl.dealer_location_id\n",
    "left join hive.l2_retail.odhsb_sbv5_st_txn_contact cus on cus.txn_id = sj.service_order_id and contact_type = 0\n",
    "where\n",
    "--actiontable.SJ_ID = ''\n",
    "actiontable.actionday >= Date('2022-01-01')\n",
    "--technician_table.expert_id is not null and techtype.dtl_sptech_id is not null\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "kronos =  pd.read_sql(sql, presto_edp)\n",
    "kronos.location_descr = kronos.location_descr.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot route of techs for 1 day on map\n",
    "day_in_tampa = kronos[(kronos.market_location== 'CLEVELAND') & (kronos.ActionDay == '2022-03-04') & (~kronos.expert_name.isna())][['SJ_ID','expert_name','addr_line_1','address_city','addr_state','cust_zip','ActType','ActionDay','ActionStart','ActionFinish']].drop_duplicates()\n",
    "day_in_tampa = day_in_tampa[day_in_tampa.ActType == 'EnRoute']\n",
    "day_in_tampa.ActionFinish = pd.to_datetime(day_in_tampa.ActionFinish)\n",
    "day_in_tampa['ActionStart'] = pd.to_datetime(day_in_tampa.ActionStart)\n",
    "day_in_tampa['duration'] =  (day_in_tampa.ActionFinish -day_in_tampa.ActionStart).astype('timedelta64[m]')\n",
    "day_in_tampa['adr_lat_lon'] = day_in_tampa.apply(geocode_address, axis = 1)\n",
    "day_in_tampa['lat'] = day_in_tampa['adr_lat_lon'].apply(lambda x: x[0])\n",
    "day_in_tampa['lon'] = day_in_tampa['adr_lat_lon'].apply(lambda x: x[1])\n",
    "\n",
    "m = folium.Map(list(tuple([demand_market_nooutliers.lat.iloc[0],demand_market_nooutliers.lon.iloc[0]])))\n",
    "route_points = folium.map.FeatureGroup('jobs').add_to(m)\n",
    "for index, each in day_in_tampa.iterrows(): \n",
    "#     print(each)\n",
    "    cm = folium.CircleMarker(location=[each.lat, each.lon],\n",
    "                                radius = 3,\n",
    "    #                             popup=str(el)+\" m\",\n",
    "                                fill=True, # Set fill to True\n",
    "                                fill_color='green',\n",
    "                                color = 'green',\n",
    "                                fill_opacity=0.7,\n",
    "                                line_opacity=0.7,\n",
    "                                name = 'stops',\n",
    "                                control=True)\n",
    "route_points.add_child(cm)\n",
    "\n",
    "for index, each in day_in_tampa.groupby(['expert_name']): \n",
    "    expert = each.expert_name.str.lower().values[0]\n",
    "    routes = folium.map.FeatureGroup('{}_routes'.format(expert)).add_to(m)\n",
    "    duration = each['duration'].sum()\n",
    "    starting_location = list(tech_locations[tech_locations.Name.str.lower() == expert][['lat','lon']].astype('float').to_records(index=False))\n",
    "    cordinates =  starting_location + list(each.sort_values(by = ['ActionStart'])[['lat','lon']].astype('float').to_records(index=False))\n",
    "    line = folium.PolyLine(cordinates, color = 'blue')\n",
    "    routes.add_child(line)\n",
    "folium.LayerControl().add_to(m)\n",
    "# m.save('todays_route.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "kronos_cleveland = kronos[(kronos.market_location== 'CLEVELAND') & (kronos.ActType == 'EnRoute') & (~kronos.expert_name.isna())][['SJ_ID','expert_name','addr_line_1','address_city','addr_state','cust_zip','ActionDay']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "kronos_cleveland['cust_lat_lon'] = kronos_cleveland.apply(geocode_address, axis = 1)\n",
    "kronos_cleveland['lat'] = kronos_cleveland['cust_lat_lon'].apply(lambda x: x[0])\n",
    "kronos_cleveland['lon'] = kronos_cleveland['cust_lat_lon'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "kronos_cleveland = kronos_cleveland[kronos_cleveland.cust_lat_lon != 'error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kronos_cleveland' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-d47fa7beab41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkronos_cleveland\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ActionDay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_route_metrics_fun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'kronos_cleveland' is not defined"
     ]
    }
   ],
   "source": [
    "kronos_cleveland.groupby(['ActionDay']).apply(current_route_metrics_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_route_metrics = pd.DataFrame(current_route_metrics, columns= ['expert_name', 'action_day','distance','duration'])\n",
    "current_route_metrics.columns = ['expert_name', 'action_day','distance','duration']\n",
    "last_week_current_setup = current_route_metrics[current_route_metrics.action_day>'2022-03-01'].groupby(['expert_name']).agg({'distance':'sum', 'duration':'sum', 'action_day':'count'}).reset_index()\n",
    "last_week_current_setup['avg_duration'] = last_week_current_setup.duration/last_week_current_setup.action_day\n",
    "last_week_current_setup['avg_distance'] = last_week_current_setup.distance/last_week_current_setup.action_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.28292682926829"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_week_current_setup.distance.sum()/last_week_current_setup.action_day.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_data = current_route_metrics[current_route_metrics.action_day>'2022-03-01'].sort_values(by = 'action_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposed setup\n",
    "assign_centroids = tabular_analysis_level2[['centroid_lat','centroid_lon','assigned_clusters_level1']]\n",
    "assign_centroids[['centroid_lat','centroid_lon']] = assign_centroids[['centroid_lat','centroid_lon']].astype(float)\n",
    "assign_centroids = assign_centroids.reset_index()\n",
    "def nearest_centriod(point):\n",
    "#     print(point['lat'])\n",
    "    job_lat = float(point['lat'])\n",
    "    job_lon = float(point['lon'])\n",
    "    \n",
    "    distances = assign_centroids.apply(lambda row: haversine((job_lat, job_lon), (row['centroid_lat'], row['centroid_lon']), unit=Unit.MILES), \n",
    "        axis=1)\n",
    "    return assign_centroids.loc[distances.idxmin(), 'assigned_clusters_level1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "kronos_cleveland['lat'] = kronos_cleveland['lat'].astype(float)\n",
    "kronos_cleveland['lon'] = kronos_cleveland['lon'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "kronos_cleveland['assigned_level2_clusters']  =kronos_cleveland.apply(lambda x: nearest_centriod(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastest_route(group, tech_locations):\n",
    "    cluster_num = group['assigned_level2_clusters'].unique()[0]\n",
    "    group = group[['lat','lon']].drop_duplicates()\n",
    "    expert_name_for_route = tabular_analysis_level2[tabular_analysis_level2.assigned_clusters_level1 == cluster_num]['assigned_tech_name'].values[0]\n",
    "    starting_address_route=  tech_locations[tech_locations.Name == expert_name_for_route.lower()][['lat','lon']].drop_duplicates()\n",
    "    sorted_jobs, dur = get_path_osrm(group[['lat','lon']], starting_address_route.lat.values, starting_address_route.lon.values)\n",
    "#     print(group)\n",
    "#     print(sorted_jobs)\n",
    "#     print(list(range(1,len(group))))\n",
    "    sorted_jobs['job_sequence'] = list(range(1,len(group)+2))\n",
    "    sorted_jobs['cluster_num'] = cluster_num\n",
    "    return(sorted_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_sorted_list_jobs = pd.DataFrame()\n",
    "for each in day_in_tampa.assigned_level2_clusters.unique():\n",
    "    group = day_in_tampa[day_in_tampa.assigned_level2_clusters == each]\n",
    "    master_sorted_list_jobs = master_sorted_list_jobs.append(fastest_route(group, tech_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_sorted_list_jobs = master_sorted_list_jobs.merge(tabular_analysis_level2[['assigned_clusters_level1','assigned_tech_name']], left_on = 'cluster_num', right_on = 'assigned_clusters_level1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expert_name\n",
       "Eric Fielman              40.0\n",
       "Keon Harris               97.0\n",
       "Rizal Bustinza Melgar     91.0\n",
       "Robert Graffy             96.0\n",
       "Steve Dehne               43.0\n",
       "Wally Farrell            188.0\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_in_tampa.groupby(['expert_name'])['duration'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assigned_tech_name\n",
       "ERIC FIELMAN      43.9\n",
       "KEON HARRIS       25.2\n",
       "KYLE CHUBB        57.3\n",
       "Rizal Bustinza    80.6\n",
       "Robert Graffy     50.0\n",
       "Steve Dehne       30.2\n",
       "Wally Farrell     99.4\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_sorted_list_jobs.groupby(['assigned_tech_name'])['duration'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tech_zone = folium.Map(list(tuple([demand_market_nooutliers.lat.iloc[0],demand_market_nooutliers.lon.iloc[0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_points = folium.map.FeatureGroup('jobs').add_to(m_tech_zone)\n",
    "for index, each in day_in_tampa.iterrows(): \n",
    "#     print(each)\n",
    "    folium.CircleMarker(location=[each.lat, each.lon],\n",
    "                                radius = 3,\n",
    "    #                             popup=str(el)+\" m\",\n",
    "                                fill=True, # Set fill to True\n",
    "                                fill_color='green',\n",
    "                                color = 'green',\n",
    "                                fill_opacity=0.7,\n",
    "                                line_opacity=0.7,\n",
    "                                name = 'stops',\n",
    "                                control=True).add_to(m_tech_zone)\n",
    "route_points.add_child(cm)\n",
    "\n",
    "    \n",
    "routes = folium.map.FeatureGroup('proposed_routes').add_to(m_tech_zone)\n",
    "for index, each in day_in_tampa.groupby(['assigned_level2_clusters']):    \n",
    "#     duration = each[each.ActType == 'EnRoute']['duration'].sum()\n",
    "    cm = folium.Marker(location=[each.lat.values[0], each.lon.values[0]],\n",
    "                           popup = [each.expert_name.values[0]],\n",
    "                           icon=folium.Icon(color='yellow', icon='male', prefix='fa')).add_to(m)\n",
    "#     color_value = tech_names_colors[tech_names_colors.expert_name == each.expert_name.values[0]]['color'].values[0]\n",
    "    cordinates = list(each.sort_values(by = ['ActionStart'])[['lat','lon']].astype('float').to_records(index=False))\n",
    "    folium.PolyLine(cordinates, color = 'yellow').add_to(m_tech_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_jobs, dur = get_path_osrm(test_case[['lat','lon']].drop_duplicates(), starting_address_route.lat.values, starting_address_route.lon.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28.5156479</td>\n",
       "      <td>-82.5735662</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>28.4849373</td>\n",
       "      <td>-82.605064</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>28.476079</td>\n",
       "      <td>-82.602346</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>28.477745</td>\n",
       "      <td>-82.523465</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>28.506</td>\n",
       "      <td>-82.497724</td>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>28.5552719</td>\n",
       "      <td>-82.3878709</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>28.359761</td>\n",
       "      <td>-82.572482</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         lat          lon  duration\n",
       "0      0  28.5156479  -82.5735662       0.0\n",
       "1      3  28.4849373   -82.605064       4.9\n",
       "2      4   28.476079   -82.602346       6.4\n",
       "3      0   28.477745   -82.523465      19.0\n",
       "4      2      28.506   -82.497724      12.3\n",
       "5      1  28.5552719  -82.3878709      19.6\n",
       "6      0   28.359761   -82.572482      37.2"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.5156479</td>\n",
       "      <td>-82.5735662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lat          lon\n",
       "3  28.5156479  -82.5735662"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_locations[tech_locations.Name == test_case.expert_name.unique()[0].lower()][['lat','lon']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tech_zone.save('proposed_routes.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) Demand forcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presto_edp = atlas.Presto(environment = \"presto://{}:{}@edp-workbench-adhoc.edp.prd.aws.asurion.net:18443/hive\").connect()\n",
    "\n",
    "sql_bookings = \"\"\"\n",
    "select \n",
    "    bookings.service_job_id,\n",
    "    bookings.booking_date,\n",
    "    bookings.market,\n",
    "    dtl_visitevidencetype,\n",
    "    max(bookings.total_visits_per_job) total_visits_per_job\n",
    "    from \n",
    "    hive.rtm_analytics.v_l3_w2_bookings bookings\n",
    "    where\n",
    "    bookings.booking_date > date('2021-01-01')\n",
    "    group by\n",
    "    bookings.service_job_id,\n",
    "    bookings.booking_date,\n",
    "    bookings.market,\n",
    "    dtl_visitevidencetype\n",
    "\"\"\"\n",
    "bookings = pd.read_sql(sql_bookings, presto_edp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_tampa = bookings[bookings.market== 'TAMPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bookings_tampa = bookings_tampa[bookings_tampa.dtl_visitevidencetype !='No Evidence of Visit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_tampa.booking_date = pd.to_datetime(bookings_tampa.booking_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_tampa_ts= bookings_tampa[['booking_date','service_job_id']].groupby(pd.Grouper(key=\"booking_date\", freq=\"1d\")).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bookings_tampa_ts[bookings_tampa_ts.ds == '2022-02-07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_tampa_ts = bookings_tampa_ts.set_index(bookings_tampa_ts.booking_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "bookings_tampa_ts.service_job_id.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fbprophet\n",
    "from fbprophet import Prophet\n",
    "\n",
    "# Initialize the Model\n",
    "model=Prophet()\n",
    "bookings_tampa_ts.columns= ['ds', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(bookings_tampa_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dates=model.make_future_dataframe(periods=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(future_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[prediction.ds>='2022-02-18'].groupby(pd.Grouper(key=\"ds\", freq=\"1w\")).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the predicted projection\n",
    "model.plot(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Visualize Each Components[Trends,yearly]\n",
    "model.plot_components(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Making 107 forecasts with cutoffs between 2021-10-26 00:00:00 and 2022-02-09 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>yhat</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>y</th>\n",
       "      <th>cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>25.049599</td>\n",
       "      <td>11.154835</td>\n",
       "      <td>39.082233</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>22.813918</td>\n",
       "      <td>9.065079</td>\n",
       "      <td>36.548217</td>\n",
       "      <td>8</td>\n",
       "      <td>2021-10-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>28.028051</td>\n",
       "      <td>13.900215</td>\n",
       "      <td>40.787740</td>\n",
       "      <td>12</td>\n",
       "      <td>2021-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-30</td>\n",
       "      <td>7.940426</td>\n",
       "      <td>-5.234542</td>\n",
       "      <td>21.955028</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>7.276570</td>\n",
       "      <td>-6.479217</td>\n",
       "      <td>20.995372</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds       yhat  yhat_lower  yhat_upper   y     cutoff\n",
       "0 2021-10-27  25.049599   11.154835   39.082233  13 2021-10-26\n",
       "1 2021-10-28  22.813918    9.065079   36.548217   8 2021-10-27\n",
       "2 2021-10-29  28.028051   13.900215   40.787740  12 2021-10-28\n",
       "3 2021-10-30   7.940426   -5.234542   21.955028   0 2021-10-29\n",
       "4 2021-10-31   7.276570   -6.479217   20.995372   0 2021-10-30"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fbprophet.diagnostics import cross_validation\n",
    "df_cv = cross_validation(model, initial='200 days', period='1 days', horizon = '1 days')\n",
    "df_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Skipping MAPE because y close to 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mdape</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 days</td>\n",
       "      <td>134.623488</td>\n",
       "      <td>11.602736</td>\n",
       "      <td>9.055002</td>\n",
       "      <td>0.482977</td>\n",
       "      <td>0.813084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horizon         mse       rmse       mae     mdape  coverage\n",
       "0  1 days  134.623488  11.602736  9.055002  0.482977  0.813084"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fbprophet.diagnostics import performance_metrics\n",
    "df_p = performance_metrics(df_cv)\n",
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "fig = plot_cross_validation_metric(df_cv, metric='rmse')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
